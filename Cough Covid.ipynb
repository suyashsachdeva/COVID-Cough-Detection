{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cough analysis \n",
    "Here cough analysis is done through mfcc of the sound, this will convert our dataset into reduced numpy array which will be easy to train. Then we pass it through a RNN model that consist of 2 LSTM layer. We are currently planning to test its  accuracy with and with the embedding layer.\n",
    "Embedding layer is basically a dense layer without biases. And it is added with the purpose to learn the relations between the words or any other format of data such that it becomes more easy of the recurrent network to learn the data making it act like a unsuperviesed layer of the network(I am not sure about this point) But any ways it is similar to the spatial transform netowrk layer in any convolutional neurl network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.preprocessing.sequence as sequence\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "\n",
    "import librosa as lb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import json\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "In preprocessing we are using the library librosa and json to get sound and cough prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r\"C:\\Users\\suyash\\Desktop\\cough detection dataset\"\n",
    "files = os.listdir(data)\n",
    "xtrain = []\n",
    "ytrain = []\n",
    "for c, file in enumerate(files):\n",
    "    if file[-4:] == \"json\":\n",
    "        file = open(data+\"/\"+file)\n",
    "        txt = json.load(file)\n",
    "        txt = txt['cough_detected']\n",
    "        ytrain.append(txt)\n",
    "    else:\n",
    "        y, sr = lb.load(data+\"/\"+file)\n",
    "        mfccs_features = lb.feature.mfcc(y=y, sr=sr, n_mfcc=16)\n",
    "        xtrain.append(mfccs_features)\n",
    "    if c>1998:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in xtrain:\n",
    "    shape = np.array(x).shape\n",
    "    l = (shape[1] - shape[1]%4)/4\n",
    "    new = x[:,:int(l*4)]\n",
    "    # print(x.shape)\n",
    "    new = np.reshape(new, (64, int(l)))\n",
    "    new = sequence.pad_sequences(new, maxlen = 120, padding=\"post\")\n",
    "    new = np.reshape(new, (120, 64))\n",
    "    xtrain[xtrain.index(x)] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = np.array([np.array(float(x)) for x in ytrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr = []\n",
    "for x in xtrain:    \n",
    "    xtr.append(new)\n",
    "xtrain = np.array(xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 120, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"xtrain.npy\", xtrain)\n",
    "# np.save(\"ytrain.npy\", ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(inp):\n",
    "    inputs = layers.Input(inp)\n",
    "    lstm1 = layers.LSTM(64, activation=\"relu\",return_sequences=True)(inputs)\n",
    "    lstm2 = layers.LSTM(32, activation=\"relu\", return_sequences=False)(lstm1)\n",
    "    dense1 = layers.Dense(16, activation=\"relu\")(lstm2)\n",
    "    dense2 = layers.Dense(1, activation=\"relu\")(dense1)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=dense2, name=\"cough_detection\")\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential([\n",
    "#     layers.LSTM(64, activation=\"relu\",return_sequences=True),\n",
    "#     layers.LSTM(32, activation=\"relu\", return_sequences=False),\n",
    "#     layers.Dense(16, activation=\"relu\"),\n",
    "#     layers.Dense(1, activation=\"relu\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(120, 64)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cough_detection\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 120, 64)]         0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 120, 64)           33024     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,985\n",
      "Trainable params: 45,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='MSE', optimizer=Adam(learning_rate=1e-7), metrics=['accuracy'])\n",
    "model.fit(xtrain, ytrain, epochs=300, verbose=1, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24522549]] 0.0155\n",
      "[[0.7573408]] 0.9609\n",
      "[[0.25434482]] 0.1643\n",
      "[[0.78587335]] 0.9301\n",
      "[[0.10959158]] 0.0482\n",
      "[[0.76434195]] 0.9968\n",
      "[[0.7829189]] 0.0735\n",
      "[[0.23109436]] 0.0306\n",
      "[[0.79022884]] 0.7811\n",
      "[[0.14514093]] 0.0307\n",
      "[[0.79339397]] 0.8937\n",
      "[[0.7876431]] 0.9883\n",
      "[[0.7927503]] 0.9456\n",
      "[[0.79091614]] 0.9959\n",
      "[[0.78934705]] 0.9536\n",
      "[[0.7920141]] 0.9712\n",
      "[[0.7469171]] 0.824\n",
      "[[0.12001724]] 0.0576\n",
      "[[0.3763579]] 0.3009\n",
      "[[0.76733494]] 0.8109\n",
      "[[0.08062581]] 0.0632\n",
      "[[0.78584653]] 0.9882\n",
      "[[0.7940916]] 0.9794\n",
      "[[0.7838974]] 0.985\n",
      "[[0.79065686]] 0.4277\n",
      "[[0.6126307]] 0.6911\n",
      "[[0.7966045]] 0.9664\n",
      "[[0.774235]] 0.9947\n",
      "[[0.7868097]] 0.9828\n",
      "[[0.79879797]] 0.0456\n",
      "[[0.79485226]] 0.0246\n",
      "[[0.7908144]] 0.9472\n",
      "[[0.7506182]] 0.9917\n",
      "[[0.7868932]] 0.9854\n",
      "[[0.79001224]] 0.9974\n",
      "[[0.67672455]] 0.9794\n",
      "[[0.11569441]] 0.3147\n",
      "[[0.79042804]] 0.9948\n",
      "[[0.78840315]] 0.9729\n",
      "[[0.28359267]] 0.0088\n",
      "[[0.7798016]] 0.5799\n",
      "[[0.78633964]] 0.2677\n",
      "[[0.7904539]] 0.9961\n",
      "[[0.78314734]] 0.8904\n",
      "[[0.5515471]] 0.2216\n",
      "[[0.79239345]] 0.9734\n",
      "[[0.7819437]] 0.9594\n",
      "[[0.6805744]] 0.9818\n",
      "[[0.7920438]] 0.8955\n",
      "[[0.7477657]] 0.958\n",
      "[[0.72203594]] 0.9437\n",
      "[[0.78224754]] 0.2098\n",
      "[[0.785246]] 0.9507\n",
      "[[0.5059125]] 0.115\n",
      "[[0.7974502]] 0.9674\n",
      "[[0.7896588]] 0.9128\n",
      "[[0.14098941]] 0.0294\n",
      "[[0.7942158]] 0.9962\n",
      "[[0.7965665]] 0.9751\n",
      "[[0.2064597]] 0.0564\n",
      "[[0.11934748]] 0.5919\n",
      "[[0.7612952]] 0.0236\n",
      "[[0.7904947]] 0.9943\n",
      "[[0.6319386]] 0.1701\n",
      "[[0.7842224]] 0.6856\n",
      "[[0.7783969]] 0.9782\n",
      "[[0.78240037]] 0.9743\n",
      "[[0.78450453]] 0.0884\n",
      "[[0.7499088]] 0.0139\n",
      "[[0.7930572]] 0.9911\n",
      "[[0.2739816]] 0.3216\n",
      "[[0.78175986]] 0.3747\n",
      "[[0.7911844]] 0.9941\n",
      "[[0.7805864]] 0.9531\n",
      "[[0.7764919]] 0.9926\n",
      "[[0.7832097]] 0.9775\n",
      "[[0.7918204]] 0.9504\n",
      "[[0.7493331]] 0.0373\n",
      "[[0.77738225]] 0.9815\n",
      "[[0.163443]] 0.3393\n",
      "[[0.7913666]] 0.9334\n",
      "[[0.62919664]] 0.8023\n",
      "[[0.6472806]] 0.8648\n",
      "[[0.16006145]] 0.0399\n",
      "[[0.7727363]] 0.6614\n",
      "[[0.7306299]] 0.0964\n",
      "[[0.79279304]] 0.9973\n",
      "[[0.7663851]] 0.99\n",
      "[[0.79174757]] 0.9877\n",
      "[[0.14578864]] 0.0201\n",
      "[[0.49028948]] 0.9822\n",
      "[[0.66149867]] 0.9089\n",
      "[[0.7832012]] 0.9699\n",
      "[[0.7286483]] 0.2798\n",
      "[[0.7804767]] 0.9078\n",
      "[[0.78614295]] 0.933\n",
      "[[0.70150465]] 0.579\n",
      "[[0.7494159]] 0.922\n",
      "[[0.21414612]] 0.0425\n",
      "[[0.7918056]] 0.8775\n"
     ]
    }
   ],
   "source": [
    "for x in range(100):  \n",
    "    print(model.predict(xtr[x].reshape(1,120,64)), ytrain[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1000):  \n",
    "    print(model.predict(xtr[x].reshape(1,120,64)), ytrain[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final1000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"C:\\Users\\suyash\\Desktop\\KACHRA\\laohub\\Smile in Pain\\Ajgar Ke Jalve\\Artificiall Intelligence\\Neural Networks\\Supervised Learning\\Recurrent Nets\\RNN\\Audio\\final.h5\"\n",
    "model = models.load_model(file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8934747c923e747831e0f17a40e9012e1def99ed1de5f3713c68cc42b4047f71"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
